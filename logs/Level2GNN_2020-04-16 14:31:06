MPNNX
<models.trainLevel2GNN.WrapperLevel2GNN object at 0x7f8d7f464cd0>
('Manual torch seed: ', 1772727637)
KFold: 1 x 10
('Optimizer: ', 'Adam')
class Level2GNN(torch.nn.Module):
    def __init__(self, outSize, layerType=GCNConv, maxNode=10000):
        super(Level2GNN, self).__init__()

        self.LAYER_TYPE = layerType
        self.LAYERS = []

        N = 5
        for i in range(N):
            layer = self.LAYER_TYPE(config.EMBED_DIM, config.EMBED_DIM)
            self.LAYERS.append(layer)

        self.act = F.relu

        self.linear1 = Linear(config.EMBED_DIM, config.EMBED_DIM)
        self.linear2 = Linear(config.EMBED_DIM, outSize)

        self.nodesEmbedding = torch.nn.Embedding(num_embeddings=maxNode + 1, embedding_dim=config.EMBED_DIM)
        self.nodesEmbedding.weight.data.uniform_(0.001, 0.3)


        # self.linear1.weight.data.uniform_(0.001, 0.3)
        self.linear2.weight.data.uniform_(0.001, 0.3)

        # Molecule graph neural net

    def my_reset_params(self, tensor, size=10):
        bound = 1.0 / math.sqrt(size)
        if tensor is not None:
            tensor.data.uniform_(0.0, bound)

    def forward(self, x, edges):

        x = self.nodesEmbedding(x)
        x = x.squeeze()

        for i in range(config.N_LAYER_LEVEL_2):
            x = self.LAYERS[i](x, edges)
            x = F.relu(x)
        return x

    def calOut(self, x, keyIds):
        o = x[keyIds]
        # o = self.linear1(o)
        # o = F.relu(o)
        o = self.linear2(o)
        o2 = F.relu(o)
        return o2

('Num Graph Layer: ', 3)
Training raw path: /home/anhnd/DTI Project/Codes/G3N/data/NTimeKFold/ATCInchikeySideEffectByDrug.txt_P3_0_0
('Number of substructures, proteins, pathways, drugs, se: ', 888, 1448, 330, 808, 331)
((646, 2666), (81, 2666), (646, 331), (81, 331))
((646, 331), (646, 331), 92145.87, 59640.0)
('Error: ', tensor(0.2405, grad_fn=<MseLossBackward>))
('Train: AUC, AUPR: ', 0.5467389945151736, 0.3120246866865285)
