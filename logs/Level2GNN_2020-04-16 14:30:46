MPNNX
<models.trainLevel2GNN.WrapperLevel2GNN object at 0x7f3f4d27ba10>
('Manual torch seed: ', 1772727637)
KFold: 1 x 10
('Optimizer: ', 'Adam')
class Level2GNN(torch.nn.Module):
    def __init__(self, outSize, layerType=GCNConv, maxNode=10000):
        super(Level2GNN, self).__init__()

        self.LAYER_TYPE = layerType
        self.LAYERS = []

        N = 5
        for i in range(N):
            layer = self.LAYER_TYPE(config.EMBED_DIM, config.EMBED_DIM)
            self.LAYERS.append(layer)

        self.act = F.relu

        self.linear1 = Linear(config.EMBED_DIM, config.EMBED_DIM)
        self.linear2 = Linear(config.EMBED_DIM, outSize)

        self.nodesEmbedding = torch.nn.Embedding(num_embeddings=maxNode + 1, embedding_dim=config.EMBED_DIM)
        self.nodesEmbedding.weight.data.uniform_(0.001, 0.3)


        # self.linear1.weight.data.uniform_(0.001, 0.3)
        self.linear2.weight.data.uniform_(0.001, 0.3)

        # Molecule graph neural net

    def my_reset_params(self, tensor, size=10):
        bound = 1.0 / math.sqrt(size)
        if tensor is not None:
            tensor.data.uniform_(0.0, bound)

    def forward(self, x, edges):

        x = self.nodesEmbedding(x)
        x = x.squeeze()

        for i in range(config.N_LAYER_LEVEL_2):
            x = self.LAYERS[i](x, edges)
            x = F.relu(x)
        return x

    def calOut(self, x, keyIds):
        o = x[keyIds]
        # o = self.linear1(o)
        # o = F.relu(o)
        o = self.linear2(o)
        o2 = F.relu(o)
        return o2

('Num Graph Layer: ', 3)
